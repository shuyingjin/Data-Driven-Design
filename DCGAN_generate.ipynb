{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83547583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved: bracelet_0_scene.stl\n",
      "✅ Saved: bracelet_12_scene.stl\n",
      "✅ Saved: bracelet_13_scene.stl\n",
      "✅ Saved: bracelet_14_scene.stl\n",
      "✅ Saved: bracelet_1_scene.stl\n",
      "✅ Saved: bracelet_2_scene.stl\n",
      "✅ Saved: bracelet_3_scene.stl\n",
      "✅ Saved: bracelet_6_scene.stl\n",
      "✅ Saved: bracelet_7_scene.stl\n",
      "✅ Saved: bracelet_8_scene.stl\n",
      "✅ Saved: bracelet_9_scene.stl\n",
      "✅ Saved: earrings_13_scene.stl\n",
      "✅ Saved: earrings_16_scene.stl\n",
      "✅ Saved: earrings_17_scene.stl\n",
      "✅ Saved: earrings_19_scene.stl\n",
      "✅ Saved: earrings_1_scene.stl\n",
      "✅ Saved: earrings_20_scene.stl\n",
      "✅ Saved: earrings_21_scene.stl\n",
      "✅ Saved: earrings_22_scene.stl\n",
      "✅ Saved: earrings_23_scene.stl\n",
      "✅ Saved: earrings_2_scene.stl\n",
      "✅ Saved: earrings_3_scene.stl\n",
      "✅ Saved: earrings_4_scene.stl\n",
      "✅ Saved: earrings_5_scene.stl\n",
      "✅ Saved: earrings_7_scene.stl\n",
      "✅ Saved: earrings_8_scene.stl\n",
      "✅ Saved: earrings_9_scene.stl\n",
      "✅ Saved: necklace_10_scene.stl\n",
      "✅ Saved: necklace_11_scene.stl\n",
      "✅ Saved: necklace_14_scene.stl\n",
      "✅ Saved: necklace_1_scene.stl\n",
      "✅ Saved: necklace_2_scene.stl\n",
      "✅ Saved: necklace_3_scene.stl\n",
      "✅ Saved: necklace_4_scene.stl\n",
      "✅ Saved: necklace_6_scene.stl\n",
      "✅ Saved: necklace_9_scene.stl\n",
      "✅ Saved: ring_0_scene.stl\n",
      "✅ Saved: ring_11_scene.stl\n",
      "✅ Saved: ring_12_scene.stl\n",
      "✅ Saved: ring_13_scene.stl\n",
      "✅ Saved: ring_15_scene.stl\n",
      "✅ Saved: ring_17_scene.stl\n",
      "✅ Saved: ring_18_scene.stl\n",
      "✅ Saved: ring_23_scene.stl\n",
      "✅ Saved: ring_2_scene.stl\n",
      "✅ Saved: ring_3_scene.stl\n",
      "✅ Saved: ring_4_scene.stl\n",
      "✅ Saved: ring_5_scene.stl\n",
      "✅ Saved: ring_6_scene.stl\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import trimesh\n",
    "from scipy.ndimage import zoom\n",
    "\n",
    "def stl_to_voxel(filepath, resolution=32):\n",
    "    mesh = trimesh.load_mesh(filepath)\n",
    "\n",
    "\n",
    "    mesh.apply_translation(-mesh.bounding_box.centroid)\n",
    "    scale = 1.0 / max(mesh.extents)\n",
    "    mesh.apply_scale(scale)\n",
    "\n",
    "\n",
    "    voxel_grid = mesh.voxelized(pitch=1.0 / resolution)\n",
    "    matrix = voxel_grid.matrix.astype(np.uint8)\n",
    "\n",
    "\n",
    "    matrix_resized = zoom(matrix,\n",
    "                          (resolution / matrix.shape[0],\n",
    "                           resolution / matrix.shape[1],\n",
    "                           resolution / matrix.shape[2]),\n",
    "                          order=0)  # 0 = nearest-neighbor\n",
    "    return matrix_resized\n",
    "\n",
    "\n",
    "input_folder = r\"C:\\Users\\golds\\Desktop\\Data-Driven Design\\converted_stl\"\n",
    "output_folder = r\"C:\\Users\\golds\\Desktop\\Data-Driven Design\\voxel_output\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "\n",
    "for fname in os.listdir(input_folder):\n",
    "    if fname.lower().endswith(\".stl\"):\n",
    "        fpath = os.path.join(input_folder, fname)\n",
    "        try:\n",
    "            vox = stl_to_voxel(fpath, resolution=32)\n",
    "            np.save(os.path.join(output_folder, fname.replace(\".stl\", \".npy\")), vox)\n",
    "            print(f\"✅ Saved: {fname}\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error with {fname}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8896d75d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ 跳过：voxel_dataset_combined.npy 的形状为 (49, 32, 32, 32)\n",
      "✅ 成功加载体素数据，形状为： (49, 32, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "folder_path = r\"C:\\Users\\golds\\Desktop\\Data-Driven Design\\voxel_output\"\n",
    "\n",
    "voxel_dataset = []\n",
    "expected_shape = (32, 32, 32)  # 你希望所有体素网格统一为这个形状\n",
    "\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".npy\"):\n",
    "        filepath = os.path.join(folder_path, filename)\n",
    "        voxel = np.load(filepath)\n",
    "\n",
    "        # 检查维度是否正确\n",
    "        if voxel.shape == expected_shape:\n",
    "            voxel_dataset.append(voxel)\n",
    "        else:\n",
    "            print(f\"❌ 跳过：{filename} 的形状为 {voxel.shape}\")\n",
    "\n",
    "# 转为 numpy array\n",
    "voxel_dataset = np.stack(voxel_dataset)  # 用 stack 代替 array 更安全\n",
    "\n",
    "# 保存为合并后的体素数据文件\n",
    "np.save(os.path.join(folder_path, \"voxel_dataset_combined.npy\"), voxel_dataset)\n",
    "\n",
    "print(\"✅ 成功加载体素数据，形状为：\", voxel_dataset.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5619687e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Batch shape: torch.Size([8, 1, 32, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "\n",
    "class VoxelDataset(Dataset):\n",
    "    def __init__(self, npy_path):\n",
    "        self.data = np.load(npy_path)\n",
    "        self.data = self.data.astype(np.float32)  # 转 float32\n",
    "        self.data = np.expand_dims(self.data, axis=1)  # (N, 1, 32, 32, 32) for CNN\n",
    "        self.data = self.data / self.data.max()  # 归一化为 0~1\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "# 加载数据\n",
    "dataset = VoxelDataset(r\"C:\\Users\\golds\\Desktop\\Data-Driven Design\\voxel_dataset_combined.npy\")\n",
    "dataloader = DataLoader(dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "# 查看尺寸\n",
    "for vox in dataloader:\n",
    "    print(\"✅ Batch shape:\", vox.shape)  # (8, 1, 32, 32, 32)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "326fec4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Generator3D(\n",
       "   (model): Sequential(\n",
       "     (0): ConvTranspose3d(100, 512, kernel_size=(4, 4, 4), stride=(1, 1, 1), bias=False)\n",
       "     (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (2): ReLU(inplace=True)\n",
       "     (3): ConvTranspose3d(512, 256, kernel_size=(4, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "     (4): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (5): ReLU(inplace=True)\n",
       "     (6): ConvTranspose3d(256, 128, kernel_size=(4, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "     (7): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (8): ReLU(inplace=True)\n",
       "     (9): ConvTranspose3d(128, 64, kernel_size=(4, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "     (10): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (11): ReLU(inplace=True)\n",
       "     (12): ConvTranspose3d(64, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "     (13): Sigmoid()\n",
       "   )\n",
       " ),\n",
       " Discriminator3D(\n",
       "   (model): Sequential(\n",
       "     (0): Conv3d(1, 64, kernel_size=(4, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "     (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "     (2): Conv3d(64, 128, kernel_size=(4, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "     (3): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "     (5): Conv3d(128, 256, kernel_size=(4, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "     (6): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "     (8): Conv3d(256, 1, kernel_size=(4, 4, 4), stride=(1, 1, 1), bias=False)\n",
       "     (9): Sigmoid()\n",
       "   )\n",
       " ))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 3D DCGAN Generator\n",
    "class Generator3D(nn.Module):\n",
    "    def __init__(self, latent_dim=100):\n",
    "        super(Generator3D, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            # input Z: (N, 100, 1, 1, 1)\n",
    "            nn.ConvTranspose3d(latent_dim, 512, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm3d(512),\n",
    "            nn.ReLU(True),\n",
    "            # (N, 512, 4, 4, 4)\n",
    "            nn.ConvTranspose3d(512, 256, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm3d(256),\n",
    "            nn.ReLU(True),\n",
    "            # (N, 256, 8, 8, 8)\n",
    "            nn.ConvTranspose3d(256, 128, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm3d(128),\n",
    "            nn.ReLU(True),\n",
    "            # (N, 128, 16, 16, 16)\n",
    "            nn.ConvTranspose3d(128, 64, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm3d(64),\n",
    "            nn.ReLU(True),\n",
    "            # (N, 64, 32, 32, 32)\n",
    "            nn.ConvTranspose3d(64, 1, 3, 1, 1, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# 3D DCGAN Discriminator\n",
    "class Discriminator3D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator3D, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            # input: (N, 1, 32, 32, 32)\n",
    "            nn.Conv3d(1, 64, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # (N, 64, 16, 16, 16)\n",
    "            nn.Conv3d(64, 128, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm3d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # (N, 128, 8, 8, 8)\n",
    "            nn.Conv3d(128, 256, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm3d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # (N, 256, 4, 4, 4)\n",
    "            nn.Conv3d(256, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()  # Output: real/fake score\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x).view(-1, 1)\n",
    "\n",
    "# Instantiate models\n",
    "latent_dim = 100\n",
    "generator = Generator3D(latent_dim)\n",
    "discriminator = Discriminator3D()\n",
    "\n",
    "generator, discriminator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3189ff9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], D Loss: 0.0194, G Loss: 7.6543\n",
      "Epoch [2/50], D Loss: 0.1606, G Loss: 8.2378\n",
      "Epoch [3/50], D Loss: 0.1683, G Loss: 5.9265\n",
      "Epoch [4/50], D Loss: 0.0019, G Loss: 7.6753\n",
      "Epoch [5/50], D Loss: 0.5165, G Loss: 8.9684\n",
      "Epoch [6/50], D Loss: 0.4026, G Loss: 6.9351\n",
      "Epoch [7/50], D Loss: 0.8239, G Loss: 5.5268\n",
      "Epoch [8/50], D Loss: 1.5934, G Loss: 3.2162\n",
      "Epoch [9/50], D Loss: 0.3128, G Loss: 4.7200\n",
      "Epoch [10/50], D Loss: 3.1692, G Loss: 10.8299\n",
      "Epoch [11/50], D Loss: 0.3931, G Loss: 3.4236\n",
      "Epoch [12/50], D Loss: 0.6703, G Loss: 7.2426\n",
      "Epoch [13/50], D Loss: 1.0416, G Loss: 9.0031\n",
      "Epoch [14/50], D Loss: 0.0848, G Loss: 4.6904\n",
      "Epoch [15/50], D Loss: 0.1571, G Loss: 6.5190\n",
      "Epoch [16/50], D Loss: 0.0344, G Loss: 6.1860\n",
      "Epoch [17/50], D Loss: 0.5083, G Loss: 8.5425\n",
      "Epoch [18/50], D Loss: 0.1978, G Loss: 7.7510\n",
      "Epoch [19/50], D Loss: 0.0119, G Loss: 5.3388\n",
      "Epoch [20/50], D Loss: 0.6017, G Loss: 13.6137\n",
      "Epoch [21/50], D Loss: 1.2760, G Loss: 20.3142\n",
      "Epoch [22/50], D Loss: 0.4504, G Loss: 6.2005\n",
      "Epoch [23/50], D Loss: 0.1676, G Loss: 6.8021\n",
      "Epoch [24/50], D Loss: 0.1519, G Loss: 6.6771\n",
      "Epoch [25/50], D Loss: 0.1044, G Loss: 5.6683\n",
      "Epoch [26/50], D Loss: 0.1929, G Loss: 4.7595\n",
      "Epoch [27/50], D Loss: 0.4325, G Loss: 9.9012\n",
      "Epoch [28/50], D Loss: 0.2102, G Loss: 5.4315\n",
      "Epoch [29/50], D Loss: 0.0827, G Loss: 5.7134\n",
      "Epoch [30/50], D Loss: 0.6669, G Loss: 3.5904\n",
      "Epoch [31/50], D Loss: 1.2441, G Loss: 8.6896\n",
      "Epoch [32/50], D Loss: 0.8724, G Loss: 5.6107\n",
      "Epoch [33/50], D Loss: 1.1161, G Loss: 7.0434\n",
      "Epoch [34/50], D Loss: 1.1523, G Loss: 16.2269\n",
      "Epoch [35/50], D Loss: 0.0219, G Loss: 5.3024\n",
      "Epoch [36/50], D Loss: 1.1401, G Loss: 7.6140\n",
      "Epoch [37/50], D Loss: 0.2083, G Loss: 4.3936\n",
      "Epoch [38/50], D Loss: 0.9198, G Loss: 4.6546\n",
      "Epoch [39/50], D Loss: 0.5357, G Loss: 10.1397\n",
      "Epoch [40/50], D Loss: 0.4347, G Loss: 5.1740\n",
      "Epoch [41/50], D Loss: 0.0839, G Loss: 4.9512\n",
      "Epoch [42/50], D Loss: 2.2458, G Loss: 1.1734\n",
      "Epoch [43/50], D Loss: 6.7387, G Loss: 9.3685\n",
      "Epoch [44/50], D Loss: 0.0467, G Loss: 5.7258\n",
      "Epoch [45/50], D Loss: 0.1358, G Loss: 4.0451\n",
      "Epoch [46/50], D Loss: 2.0198, G Loss: 6.7351\n",
      "Epoch [47/50], D Loss: 3.2152, G Loss: 15.6544\n",
      "Epoch [48/50], D Loss: 0.0571, G Loss: 4.3063\n",
      "Epoch [49/50], D Loss: 2.5365, G Loss: 4.3788\n",
      "Epoch [50/50], D Loss: 0.5445, G Loss: 6.9363\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# 假设你已经生成了 voxel_dataset_combined.npy 并且文件路径如下：\n",
    "npy_path = r\"C:\\Users\\golds\\Desktop\\Data-Driven Design\\voxel_dataset_combined.npy\"\n",
    "\n",
    "# 加载数据\n",
    "voxel_dataset_combined = np.load(npy_path)\n",
    "voxel_tensor = torch.tensor(voxel_dataset_combined, dtype=torch.float32).unsqueeze(1)  # shape: (N, 1, 32, 32, 32)\n",
    "\n",
    "# 构建 DataLoader\n",
    "dataset = TensorDataset(voxel_tensor)\n",
    "dataloader = DataLoader(dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "# 定义 Generator 和 Discriminator\n",
    "class Generator3D(nn.Module):\n",
    "    def __init__(self, latent_dim=100):\n",
    "        super(Generator3D, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.ConvTranspose3d(latent_dim, 512, kernel_size=4, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm3d(512),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose3d(512, 256, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm3d(256),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose3d(256, 128, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm3d(128),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose3d(128, 64, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm3d(64),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose3d(64, 1, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.model(z)\n",
    "\n",
    "class Discriminator3D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator3D, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv3d(1, 64, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv3d(64, 128, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm3d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv3d(128, 256, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm3d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv3d(256, 1, kernel_size=4, stride=1, padding=0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# 初始化模型\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "G = Generator3D().to(device)\n",
    "D = Discriminator3D().to(device)\n",
    "\n",
    "# 损失函数与优化器\n",
    "criterion = nn.BCELoss()\n",
    "optimizer_G = optim.Adam(G.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "optimizer_D = optim.Adam(D.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "\n",
    "# 训练参数\n",
    "latent_dim = 100\n",
    "epochs = 50\n",
    "\n",
    "# 训练循环\n",
    "for epoch in range(epochs):\n",
    "    for i, (real_voxels,) in enumerate(dataloader):\n",
    "        real_voxels = real_voxels.to(device)\n",
    "\n",
    "        # 训练 Discriminator\n",
    "        optimizer_D.zero_grad()\n",
    "        batch_size = real_voxels.size(0)\n",
    "        real_labels = torch.ones(batch_size, 1, 1, 1, 1).to(device)\n",
    "        fake_labels = torch.zeros(batch_size, 1, 1, 1, 1).to(device)\n",
    "\n",
    "        outputs_real = D(real_voxels)\n",
    "        d_loss_real = criterion(outputs_real, real_labels)\n",
    "\n",
    "        z = torch.randn(batch_size, latent_dim, 1, 1, 1).to(device)\n",
    "        fake_voxels = G(z)\n",
    "        outputs_fake = D(fake_voxels.detach())\n",
    "        d_loss_fake = criterion(outputs_fake, fake_labels)\n",
    "\n",
    "        d_loss = d_loss_real + d_loss_fake\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        # 训练 Generator\n",
    "        optimizer_G.zero_grad()\n",
    "        outputs = D(fake_voxels)\n",
    "        g_loss = criterion(outputs, real_labels)\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], D Loss: {d_loss.item():.4f}, G Loss: {g_loss.item():.4f}\")\n",
    "\n",
    "# 保存模型\n",
    "torch.save(G.state_dict(), \"generator3d.pth\")\n",
    "torch.save(D.state_dict(), \"discriminator3d.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6fa0c33f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ saved: generated_voxel_0.npy\n",
      "✅ saved: generated_voxel_1.npy\n",
      "✅ saved: generated_voxel_2.npy\n",
      "✅ saved: generated_voxel_3.npy\n",
      "✅ saved: generated_voxel_4.npy\n",
      "✅ saved: generated_voxel_5.npy\n",
      "✅ saved: generated_voxel_6.npy\n",
      "✅ saved: generated_voxel_7.npy\n",
      "✅ saved: generated_voxel_8.npy\n",
      "✅ saved: generated_voxel_9.npy\n",
      "✅ saved: generated_voxel_10.npy\n",
      "✅ saved: generated_voxel_11.npy\n",
      "✅ saved: generated_voxel_12.npy\n",
      "✅ saved: generated_voxel_13.npy\n",
      "✅ saved: generated_voxel_14.npy\n",
      "✅ saved: generated_voxel_15.npy\n",
      "✅ saved: generated_voxel_16.npy\n",
      "✅ saved: generated_voxel_17.npy\n",
      "✅ saved: generated_voxel_18.npy\n",
      "✅ saved: generated_voxel_19.npy\n",
      "✅ saved: generated_voxel_20.npy\n",
      "✅ saved: generated_voxel_21.npy\n",
      "✅ saved: generated_voxel_22.npy\n",
      "✅ saved: generated_voxel_23.npy\n",
      "✅ saved: generated_voxel_24.npy\n",
      "✅ saved: generated_voxel_25.npy\n",
      "✅ saved: generated_voxel_26.npy\n",
      "✅ saved: generated_voxel_27.npy\n",
      "✅ saved: generated_voxel_28.npy\n",
      "✅ saved: generated_voxel_29.npy\n",
      "✅ saved: generated_voxel_30.npy\n",
      "✅ saved: generated_voxel_31.npy\n",
      "✅ saved: generated_voxel_32.npy\n",
      "✅ saved: generated_voxel_33.npy\n",
      "✅ saved: generated_voxel_34.npy\n",
      "✅ saved: generated_voxel_35.npy\n",
      "✅ saved: generated_voxel_36.npy\n",
      "✅ saved: generated_voxel_37.npy\n",
      "✅ saved: generated_voxel_38.npy\n",
      "✅ saved: generated_voxel_39.npy\n",
      "✅ saved: generated_voxel_40.npy\n",
      "✅ saved: generated_voxel_41.npy\n",
      "✅ saved: generated_voxel_42.npy\n",
      "✅ saved: generated_voxel_43.npy\n",
      "✅ saved: generated_voxel_44.npy\n",
      "✅ saved: generated_voxel_45.npy\n",
      "✅ saved: generated_voxel_46.npy\n",
      "✅ saved: generated_voxel_47.npy\n",
      "✅ saved: generated_voxel_48.npy\n",
      "✅ saved: generated_voxel_49.npy\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "generator = generator.to(device)  # ✅ 移动模型到 GPU\n",
    "\n",
    "# 设置为评估模式\n",
    "generator.eval()\n",
    "\n",
    "# 生成 n 个体素模型\n",
    "n = 50\n",
    "with torch.no_grad():\n",
    "    noise = torch.randn(n, 100, 1, 1, 1).to(device)  # 随机噪声\n",
    "    fake_voxels = generator(noise).cpu().numpy()     # 回到 CPU\n",
    "    fake_voxels = (fake_voxels > 0.5).astype(np.uint8)  # 二值化\n",
    "\n",
    "# 保存为 .npy 文件\n",
    "for i in range(n):\n",
    "    np.save(f\"generated_voxel_{i}.npy\", fake_voxels[i, 0])\n",
    "    print(f\"✅ saved: generated_voxel_{i}.npy\")\n",
    "\n",
    "# 可视化其中一个切片\n",
    "plt.imshow(fake_voxels[0, 0, 16, :, :], cmap=\"gray\")  # 使用灰度图显示\n",
    "plt.title(\"Generated Voxel Slice (Z=16)\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "385bcb93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Exported: C:\\Users\\golds\\Desktop\\Data-Driven Design\\generated_voxel\\stl_output\\generated_voxel_0.stl\n",
      "✅ Exported: C:\\Users\\golds\\Desktop\\Data-Driven Design\\generated_voxel\\stl_output\\generated_voxel_1.stl\n",
      "✅ Exported: C:\\Users\\golds\\Desktop\\Data-Driven Design\\generated_voxel\\stl_output\\generated_voxel_10.stl\n",
      "✅ Exported: C:\\Users\\golds\\Desktop\\Data-Driven Design\\generated_voxel\\stl_output\\generated_voxel_11.stl\n",
      "✅ Exported: C:\\Users\\golds\\Desktop\\Data-Driven Design\\generated_voxel\\stl_output\\generated_voxel_12.stl\n",
      "✅ Exported: C:\\Users\\golds\\Desktop\\Data-Driven Design\\generated_voxel\\stl_output\\generated_voxel_13.stl\n",
      "✅ Exported: C:\\Users\\golds\\Desktop\\Data-Driven Design\\generated_voxel\\stl_output\\generated_voxel_14.stl\n",
      "✅ Exported: C:\\Users\\golds\\Desktop\\Data-Driven Design\\generated_voxel\\stl_output\\generated_voxel_15.stl\n",
      "✅ Exported: C:\\Users\\golds\\Desktop\\Data-Driven Design\\generated_voxel\\stl_output\\generated_voxel_16.stl\n",
      "✅ Exported: C:\\Users\\golds\\Desktop\\Data-Driven Design\\generated_voxel\\stl_output\\generated_voxel_17.stl\n",
      "✅ Exported: C:\\Users\\golds\\Desktop\\Data-Driven Design\\generated_voxel\\stl_output\\generated_voxel_18.stl\n",
      "✅ Exported: C:\\Users\\golds\\Desktop\\Data-Driven Design\\generated_voxel\\stl_output\\generated_voxel_19.stl\n",
      "✅ Exported: C:\\Users\\golds\\Desktop\\Data-Driven Design\\generated_voxel\\stl_output\\generated_voxel_2.stl\n",
      "✅ Exported: C:\\Users\\golds\\Desktop\\Data-Driven Design\\generated_voxel\\stl_output\\generated_voxel_20.stl\n",
      "✅ Exported: C:\\Users\\golds\\Desktop\\Data-Driven Design\\generated_voxel\\stl_output\\generated_voxel_21.stl\n",
      "✅ Exported: C:\\Users\\golds\\Desktop\\Data-Driven Design\\generated_voxel\\stl_output\\generated_voxel_22.stl\n",
      "✅ Exported: C:\\Users\\golds\\Desktop\\Data-Driven Design\\generated_voxel\\stl_output\\generated_voxel_23.stl\n",
      "✅ Exported: C:\\Users\\golds\\Desktop\\Data-Driven Design\\generated_voxel\\stl_output\\generated_voxel_24.stl\n",
      "✅ Exported: C:\\Users\\golds\\Desktop\\Data-Driven Design\\generated_voxel\\stl_output\\generated_voxel_25.stl\n",
      "✅ Exported: C:\\Users\\golds\\Desktop\\Data-Driven Design\\generated_voxel\\stl_output\\generated_voxel_26.stl\n",
      "✅ Exported: C:\\Users\\golds\\Desktop\\Data-Driven Design\\generated_voxel\\stl_output\\generated_voxel_27.stl\n",
      "✅ Exported: C:\\Users\\golds\\Desktop\\Data-Driven Design\\generated_voxel\\stl_output\\generated_voxel_28.stl\n",
      "✅ Exported: C:\\Users\\golds\\Desktop\\Data-Driven Design\\generated_voxel\\stl_output\\generated_voxel_29.stl\n",
      "✅ Exported: C:\\Users\\golds\\Desktop\\Data-Driven Design\\generated_voxel\\stl_output\\generated_voxel_3.stl\n",
      "✅ Exported: C:\\Users\\golds\\Desktop\\Data-Driven Design\\generated_voxel\\stl_output\\generated_voxel_30.stl\n",
      "✅ Exported: C:\\Users\\golds\\Desktop\\Data-Driven Design\\generated_voxel\\stl_output\\generated_voxel_31.stl\n",
      "✅ Exported: C:\\Users\\golds\\Desktop\\Data-Driven Design\\generated_voxel\\stl_output\\generated_voxel_32.stl\n",
      "✅ Exported: C:\\Users\\golds\\Desktop\\Data-Driven Design\\generated_voxel\\stl_output\\generated_voxel_33.stl\n",
      "✅ Exported: C:\\Users\\golds\\Desktop\\Data-Driven Design\\generated_voxel\\stl_output\\generated_voxel_34.stl\n",
      "✅ Exported: C:\\Users\\golds\\Desktop\\Data-Driven Design\\generated_voxel\\stl_output\\generated_voxel_35.stl\n",
      "✅ Exported: C:\\Users\\golds\\Desktop\\Data-Driven Design\\generated_voxel\\stl_output\\generated_voxel_36.stl\n",
      "✅ Exported: C:\\Users\\golds\\Desktop\\Data-Driven Design\\generated_voxel\\stl_output\\generated_voxel_37.stl\n",
      "✅ Exported: C:\\Users\\golds\\Desktop\\Data-Driven Design\\generated_voxel\\stl_output\\generated_voxel_38.stl\n",
      "✅ Exported: C:\\Users\\golds\\Desktop\\Data-Driven Design\\generated_voxel\\stl_output\\generated_voxel_39.stl\n",
      "✅ Exported: C:\\Users\\golds\\Desktop\\Data-Driven Design\\generated_voxel\\stl_output\\generated_voxel_4.stl\n",
      "✅ Exported: C:\\Users\\golds\\Desktop\\Data-Driven Design\\generated_voxel\\stl_output\\generated_voxel_40.stl\n",
      "✅ Exported: C:\\Users\\golds\\Desktop\\Data-Driven Design\\generated_voxel\\stl_output\\generated_voxel_41.stl\n",
      "✅ Exported: C:\\Users\\golds\\Desktop\\Data-Driven Design\\generated_voxel\\stl_output\\generated_voxel_42.stl\n",
      "✅ Exported: C:\\Users\\golds\\Desktop\\Data-Driven Design\\generated_voxel\\stl_output\\generated_voxel_43.stl\n",
      "✅ Exported: C:\\Users\\golds\\Desktop\\Data-Driven Design\\generated_voxel\\stl_output\\generated_voxel_44.stl\n",
      "✅ Exported: C:\\Users\\golds\\Desktop\\Data-Driven Design\\generated_voxel\\stl_output\\generated_voxel_45.stl\n",
      "✅ Exported: C:\\Users\\golds\\Desktop\\Data-Driven Design\\generated_voxel\\stl_output\\generated_voxel_46.stl\n",
      "✅ Exported: C:\\Users\\golds\\Desktop\\Data-Driven Design\\generated_voxel\\stl_output\\generated_voxel_47.stl\n",
      "✅ Exported: C:\\Users\\golds\\Desktop\\Data-Driven Design\\generated_voxel\\stl_output\\generated_voxel_48.stl\n",
      "✅ Exported: C:\\Users\\golds\\Desktop\\Data-Driven Design\\generated_voxel\\stl_output\\generated_voxel_49.stl\n",
      "✅ Exported: C:\\Users\\golds\\Desktop\\Data-Driven Design\\generated_voxel\\stl_output\\generated_voxel_5.stl\n",
      "✅ Exported: C:\\Users\\golds\\Desktop\\Data-Driven Design\\generated_voxel\\stl_output\\generated_voxel_6.stl\n",
      "✅ Exported: C:\\Users\\golds\\Desktop\\Data-Driven Design\\generated_voxel\\stl_output\\generated_voxel_7.stl\n",
      "✅ Exported: C:\\Users\\golds\\Desktop\\Data-Driven Design\\generated_voxel\\stl_output\\generated_voxel_8.stl\n",
      "✅ Exported: C:\\Users\\golds\\Desktop\\Data-Driven Design\\generated_voxel\\stl_output\\generated_voxel_9.stl\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import trimesh\n",
    "from skimage import measure\n",
    "\n",
    "def voxel_to_stl(voxel_grid, output_path):\n",
    "    \"\"\"\n",
    "    将体素 numpy 数组转换为 STL 网格文件\n",
    "    \"\"\"\n",
    "    voxel_grid = voxel_grid.squeeze()  # 去除多余维度 (1, 32, 32, 32) -> (32, 32, 32)\n",
    "    if voxel_grid.ndim != 3:\n",
    "        raise ValueError(f\"Unexpected voxel shape: {voxel_grid.shape}\")\n",
    "\n",
    "    verts, faces, _, _ = measure.marching_cubes(voxel_grid, level=0.5)\n",
    "    mesh = trimesh.Trimesh(vertices=verts, faces=faces)\n",
    "    mesh.export(output_path)\n",
    "    print(f\"✅ Exported: {output_path}\")\n",
    "\n",
    "def batch_convert_npy_to_stl(folder_path):\n",
    "    \"\"\"\n",
    "    遍历文件夹，将每个 .npy 文件转换为 .stl\n",
    "    \"\"\"\n",
    "    output_folder = os.path.join(folder_path, \"stl_output\")\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    npy_files = [f for f in os.listdir(folder_path) if f.endswith(\".npy\")]\n",
    "\n",
    "    if not npy_files:\n",
    "        print(\"❌ No .npy files found.\")\n",
    "        return\n",
    "\n",
    "    for fname in npy_files:\n",
    "        fpath = os.path.join(folder_path, fname)\n",
    "        voxel = np.load(fpath)\n",
    "\n",
    "        stl_name = os.path.splitext(fname)[0] + \".stl\"\n",
    "        output_path = os.path.join(output_folder, stl_name)\n",
    "\n",
    "        try:\n",
    "            voxel_to_stl(voxel, output_path)\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Failed on {fname}: {e}\")\n",
    "\n",
    "# ✅ 修改为你自己的路径：\n",
    "folder_path = r\"C:\\Users\\golds\\Desktop\\Data-Driven Design\\generated_voxel\"\n",
    "batch_convert_npy_to_stl(folder_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_pig",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
