{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8442ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The config attributes {'renderer': ['shap_e', 'ShapERenderer']} were passed to ShapEImg2ImgPipeline, but are not expected and will be ignored. Please verify your model_index.json configuration file.\n",
      "Keyword arguments {'renderer': ['shap_e', 'ShapERenderer']} are not expected by ShapEImg2ImgPipeline and will be ignored.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f943a85fb7740c0b4b88c20dd946b93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An error occurred while trying to fetch C:\\Users\\golds\\.cache\\huggingface\\hub\\models--openai--shap-e-img2img\\snapshots\\0e0aba80f08d368aaf6af9cb93583707481cc29b\\prior: Error no file named diffusion_pytorch_model.safetensors found in directory C:\\Users\\golds\\.cache\\huggingface\\hub\\models--openai--shap-e-img2img\\snapshots\\0e0aba80f08d368aaf6af9cb93583707481cc29b\\prior.\n",
      "Defaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.\n",
      "An error occurred while trying to fetch C:\\Users\\golds\\.cache\\huggingface\\hub\\models--openai--shap-e-img2img\\snapshots\\0e0aba80f08d368aaf6af9cb93583707481cc29b\\shap_e_renderer: Error no file named diffusion_pytorch_model.safetensors found in directory C:\\Users\\golds\\.cache\\huggingface\\hub\\models--openai--shap-e-img2img\\snapshots\\0e0aba80f08d368aaf6af9cb93583707481cc29b\\shap_e_renderer.\n",
      "Defaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc1cdeef50f6402aabba7447066bf671",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/99 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Generated and saved: jewelry4.glb\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# generate_jewelry2.py\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from PIL import Image\n",
    "from diffusers import ShapEImg2ImgPipeline\n",
    "from diffusers.utils import export_to_ply\n",
    "import trimesh\n",
    "\n",
    "def generate_shap_e_mesh(image_path: str, output_glb: str):\n",
    "\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "    pipe = ShapEImg2ImgPipeline.from_pretrained(\"openai/shap-e-img2img\").to(device)\n",
    "\n",
    "\n",
    "    img = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "\n",
    "    output = pipe(\n",
    "        image=img,\n",
    "        guidance_scale=10,\n",
    "        num_inference_steps=50,\n",
    "        frame_size=384,\n",
    "        output_type=\"mesh\"\n",
    "    )\n",
    "\n",
    "\n",
    "    meshes = output.images\n",
    "    mesh_meta = meshes[0] if isinstance(meshes, list) else meshes\n",
    "\n",
    "\n",
    "    ply_file = export_to_ply(mesh_meta, \"temp_shap_e.ply\")\n",
    "\n",
    "\n",
    "    mesh = trimesh.load(ply_file, force='mesh')\n",
    "    mesh.export(output_glb)\n",
    "\n",
    "\n",
    "    os.remove(ply_file)\n",
    "\n",
    "    print(f\"✅ Generated and saved: {output_glb}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    image_path = r\"C:\\Users\\golds\\Desktop\\Data-Driven Design\\generated3\\cluster_2\\cluster_2_0.png\"\n",
    "    output_glb = \"jewelry4.glb\"\n",
    "\n",
    "    generate_shap_e_mesh(image_path, output_glb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7e1ff4e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The config attributes {'renderer': ['shap_e', 'ShapERenderer']} were passed to ShapEImg2ImgPipeline, but are not expected and will be ignored. Please verify your model_index.json configuration file.\n",
      "Keyword arguments {'renderer': ['shap_e', 'ShapERenderer']} are not expected by ShapEImg2ImgPipeline and will be ignored.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71a67ab9d0a74df4a5608b04824c664d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An error occurred while trying to fetch C:\\Users\\golds\\.cache\\huggingface\\hub\\models--openai--shap-e-img2img\\snapshots\\0e0aba80f08d368aaf6af9cb93583707481cc29b\\shap_e_renderer: Error no file named diffusion_pytorch_model.safetensors found in directory C:\\Users\\golds\\.cache\\huggingface\\hub\\models--openai--shap-e-img2img\\snapshots\\0e0aba80f08d368aaf6af9cb93583707481cc29b\\shap_e_renderer.\n",
      "Defaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.\n",
      "An error occurred while trying to fetch C:\\Users\\golds\\.cache\\huggingface\\hub\\models--openai--shap-e-img2img\\snapshots\\0e0aba80f08d368aaf6af9cb93583707481cc29b\\prior: Error no file named diffusion_pytorch_model.safetensors found in directory C:\\Users\\golds\\.cache\\huggingface\\hub\\models--openai--shap-e-img2img\\snapshots\\0e0aba80f08d368aaf6af9cb93583707481cc29b\\prior.\n",
      "Defaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29c58bc9f8364b7db68287cc7e177f8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/99 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Mesh exported to: jewelry4.ply\n",
      "✅ Converted to jewelry4.glb\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from diffusers import ShapEImg2ImgPipeline\n",
    "from diffusers.utils import export_to_ply  # 用于导出 PLY\n",
    "import trimesh\n",
    "\n",
    "def main():\n",
    "    # 1. 设备\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # 2. 加载 Image→Mesh pipeline（默认 float32）\n",
    "    pipe = ShapEImg2ImgPipeline.from_pretrained(\"openai/shap-e-img2img\").to(device)\n",
    "\n",
    "    # 3. 读取并预处理你的首饰照片\n",
    "    img = Image.open(r\"C:\\Users\\golds\\Desktop\\Data-Driven Design\\generated_views\\cluster_0\\0.png\").convert(\"RGB\")\n",
    "\n",
    "    # 4. 运行 Shap‑E，获取 mesh metadata\n",
    "    output = pipe(\n",
    "        image=img,\n",
    "        guidance_scale=12,      # 控制几何贴合度，7–9 之间\n",
    "        num_inference_steps=50,  # 50–100 步，越多细节越丰富\n",
    "        frame_size=256,          # 内部 3D 分辨率\n",
    "        output_type=\"mesh\"       # 强制输出 mesh 而非 PIL 图\n",
    "    )\n",
    "    mesh_meta = output.images[0]  # MeshDecoderOutput 对象 :contentReference[oaicite:0]{index=0}\n",
    "\n",
    "    # 5. 导出为 PLY 文件\n",
    "    ply_path = export_to_ply(mesh_meta, \"jewelry4.ply\")\n",
    "    print(f\"✅ Mesh exported to: {ply_path}\")  # e.g. ./jewelry.ply :contentReference[oaicite:1]{index=1}\n",
    "\n",
    "    # 6. 用 trimesh 读取并转为 glTF (.glb)，保留 UV\n",
    "    mesh = trimesh.load(ply_path, force='mesh')\n",
    "    mesh.export(\"jewelry4.glb\", file_type=\"glb\")\n",
    "    print(\"✅ Converted to jewelry4.glb\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5512af9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[✔] piece_0_0.png → generated_views\\cluster_0\\masks\\piece_0_0.png\n",
      "[✔] piece_0_1.png → generated_views\\cluster_0\\masks\\piece_0_1.png\n",
      "[✔] piece_1_0.png → generated_views\\cluster_0\\masks\\piece_1_0.png\n",
      "[✔] piece_1_1.png → generated_views\\cluster_0\\masks\\piece_1_1.png\n",
      "全部完成！请检查 MASK_DIR 下的黑底白首饰掩膜。\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "from glob import glob\n",
    "\n",
    "# —— 配置区 ——\n",
    "# 把原始首饰图放在这里\n",
    "INPUT_DIR  = r\"C:\\Users\\golds\\Desktop\\Data-Driven Design\\generated_views\\cluster_0\\pieces\"\n",
    "# 脚本会把生成的黑白掩膜保存到这里\n",
    "MASK_DIR   = r\"C:\\Users\\golds\\Desktop\\Data-Driven Design\\generated_views\\cluster_0\\masks\"\n",
    "# 支持的图片后缀\n",
    "SUFFIXES   = (\".png\", \".jpg\", \".jpeg\")\n",
    "# Otsu 阈值后的形态学核大小\n",
    "KERNEL_SIZE_OPEN  = (5,5)\n",
    "KERNEL_SIZE_CLOSE = (7,7)\n",
    "# ———————\n",
    "\n",
    "os.makedirs(MASK_DIR, exist_ok=True)\n",
    "\n",
    "# 遍历所有图片\n",
    "for img_path in glob(os.path.join(INPUT_DIR, \"*\")):\n",
    "    if not img_path.lower().endswith(SUFFIXES):\n",
    "        continue\n",
    "\n",
    "    # 1) 读取并转灰度\n",
    "    img   = cv2.imread(img_path)\n",
    "    gray  = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # 2) Otsu 自动阈值\n",
    "    _, mask = cv2.threshold(gray, 0, 255,\n",
    "                            cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    # 3) 根据实际情况决定是否反转\n",
    "    #    这里假设「首饰」比背景亮，用上面得到的 mask 就已经是白首饰、黑背景\n",
    "    #    如果反过来，请取消下一行注释\n",
    "    # mask = 255 - mask\n",
    "\n",
    "    # 4) 形态学清理：先开运算去小噪点，再闭运算填孔\n",
    "    kernel_open  = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, KERNEL_SIZE_OPEN)\n",
    "    kernel_close = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, KERNEL_SIZE_CLOSE)\n",
    "\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN,  kernel_open)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel_close)\n",
    "\n",
    "    # 5) 保存黑白掩膜\n",
    "    fname = os.path.basename(img_path)\n",
    "    out_path = os.path.join(MASK_DIR, fname)\n",
    "    cv2.imwrite(out_path, mask)\n",
    "\n",
    "    print(f\"[✔] {fname} → {os.path.relpath(out_path)}\")\n",
    "\n",
    "print(\"全部完成！请检查 MASK_DIR 下的黑底白首饰掩膜。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64299b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\golds\\AppData\\Local\\Temp\\ipykernel_2028\\1139794905.py:58: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  img = imageio.imread(os.path.join(MASK_DIR, fn))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[✔] Loaded 4 masks, each shape = (512, 512)\n",
      "⏳ Carving voxels…\n",
      "    → Raw voxel grid: (256, 256, 256), voxels on = 322304\n",
      "⏳ Applying 3D Gaussian smoothing…\n",
      "    → After Gaussian: voxels on = 301312\n",
      "⏳ Applying 3D closing…\n",
      "    → After closing: voxels on = 300482\n",
      "⏳ Running marching_cubes…\n",
      "    → Mesh: vertices=182706, faces=365368\n",
      "⏳ Applying Laplacian smoothing…\n",
      "    → After smoothing: vertices=182706, faces=365368\n",
      "✅ Saved smoothed mesh to: C:\\Users\\golds\\Desktop\\Data-Driven Design\\smoothed_mesh.ply\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy.ndimage as ndi\n",
    "from scipy.ndimage import binary_closing, generate_binary_structure\n",
    "import trimesh\n",
    "from trimesh.smoothing import filter_laplacian\n",
    "\n",
    "# ——— 参数区 ———\n",
    "# 输入：若干二值掩膜（bool ndarray），shape 相同\n",
    "MASK_DIR        = r\"C:\\Users\\golds\\Desktop\\Data-Driven Design\\generated_views\\cluster_0\\masks\"\n",
    "# 输出模型\n",
    "OUTPUT_MESH     = r\"C:\\Users\\golds\\Desktop\\Data-Driven Design\\smoothed_mesh.ply\"\n",
    "\n",
    "# 体素分辨率（越大越细腻，显存/内存消耗越高）\n",
    "RES             = 256\n",
    "# 三维高斯模糊的 sigma\n",
    "GAUSS_SIGMA     = 1.2\n",
    "# 闭运算结构元素与迭代次数\n",
    "CLOSING_STRUCT  = generate_binary_structure(3, 1)\n",
    "CLOSING_ITERS   = 1\n",
    "# Laplacian 平滑参数\n",
    "LAPLACIAN_LAMB  = 0.5\n",
    "LAPLACIAN_ITERS = 15\n",
    "# ———————————\n",
    "\n",
    "def carve_voxels(mask_list, res=RES):\n",
    "    \"\"\"\n",
    "    简单体素 carve：根据多视角二值掩膜 mask_list（list of bool ndarray），\n",
    "    在三维体素空间中保留所有视角投影内的体素。\n",
    "    \"\"\"\n",
    "    # 假设所有 mask 都是正方形，统一大小\n",
    "    H, W = mask_list[0].shape\n",
    "    grid = np.ones((res, res, res), dtype=bool)\n",
    "\n",
    "    # 投影：这里简单正交投影，视角可自行扩展\n",
    "    for mask in mask_list:\n",
    "        for z in range(res):\n",
    "            # 将第 z 层投影到 2D mask，保留在 mask 内的体素\n",
    "            # 映射关系：体素坐标 [i,j,z] → 像素坐标 [i*H/res, j*W/res]\n",
    "            ii = (np.arange(res) * (H-1) / (res-1)).astype(int)\n",
    "            jj = (np.arange(res) * (W-1) / (res-1)).astype(int)\n",
    "            # 外积生成 mask 层\n",
    "            m2d = mask[np.ix_(ii, jj)]\n",
    "            grid[:, :, z] &= m2d\n",
    "\n",
    "    return grid\n",
    "\n",
    "def main():\n",
    "    # 1) 读取所有 mask 图，并转换为 bool ndarray\n",
    "    mask_files = sorted([f for f in os.listdir(MASK_DIR)\n",
    "                         if f.lower().endswith((\".png\",\".jpg\",\".jpeg\"))])\n",
    "    masks = []\n",
    "    for fn in mask_files:\n",
    "        import imageio\n",
    "        img = imageio.imread(os.path.join(MASK_DIR, fn))\n",
    "        # 灰度化并二值化（阈值 128 可根据图片调整）\n",
    "        if img.ndim == 3:\n",
    "            img = np.dot(img[...,:3], [0.299,0.587,0.114])\n",
    "        masks.append((img > 128))\n",
    "    print(f\"[✔] Loaded {len(masks)} masks, each shape = {masks[0].shape}\")\n",
    "\n",
    "    # 2) carve 出原始体素网格\n",
    "    print(\"⏳ Carving voxels…\")\n",
    "    grid = carve_voxels(masks, res=RES)\n",
    "    print(f\"    → Raw voxel grid: {grid.shape}, voxels on = {grid.sum()}\")\n",
    "\n",
    "    # 3) 三维高斯平滑 + 二值化\n",
    "    print(\"⏳ Applying 3D Gaussian smoothing…\")\n",
    "    gray = grid.astype(float)\n",
    "    gray = ndi.gaussian_filter(gray, sigma=GAUSS_SIGMA)\n",
    "    grid = gray > 0.5\n",
    "    print(f\"    → After Gaussian: voxels on = {grid.sum()}\")\n",
    "\n",
    "    # 4) 三维闭运算（closing）\n",
    "    print(\"⏳ Applying 3D closing…\")\n",
    "    grid = binary_closing(grid, structure=CLOSING_STRUCT, iterations=CLOSING_ITERS)\n",
    "    print(f\"    → After closing: voxels on = {grid.sum()}\")\n",
    "\n",
    "    # 5) marching cubes 生成三角网格\n",
    "    print(\"⏳ Running marching_cubes…\")\n",
    "    mesh = trimesh.voxel.ops.matrix_to_marching_cubes(grid, pitch=1.0/RES)\n",
    "    print(f\"    → Mesh: vertices={len(mesh.vertices)}, faces={len(mesh.faces)}\")\n",
    "\n",
    "    # 6) Laplacian 平滑\n",
    "    print(\"⏳ Applying Laplacian smoothing…\")\n",
    "    filter_laplacian(mesh, lamb=LAPLACIAN_LAMB, iterations=LAPLACIAN_ITERS)\n",
    "    print(f\"    → After smoothing: vertices={len(mesh.vertices)}, faces={len(mesh.faces)}\")\n",
    "\n",
    "    # 7) 导出\n",
    "    mesh.export(OUTPUT_MESH)\n",
    "    print(f\"✅ Saved smoothed mesh to: {OUTPUT_MESH}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3ee6f13f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ 正在加载 PLY：C:\\Users\\golds\\Desktop\\Data-Driven Design\\smoothed_mesh.ply\n",
      "    → 顶点数：182706, 面数：365368\n",
      "⏳ 导出为 GLB：C:\\Users\\golds\\Desktop\\Data-Driven Design\\smoothed_mesh.glb\n",
      "✅ 导出完成！你现在可以在 Blender 里用 “File → Import → glTF 2.0” 打开它了。\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import trimesh\n",
    "\n",
    "# —— 配置区 ——\n",
    "# 把下面路径改成你的 PLY 输入路径和要输出的 GLB 路径\n",
    "INPUT_PLY  = r\"C:\\Users\\golds\\Desktop\\Data-Driven Design\\smoothed_mesh.ply\"\n",
    "OUTPUT_GLB = r\"C:\\Users\\golds\\Desktop\\Data-Driven Design\\smoothed_mesh.glb\"\n",
    "# ————————\n",
    "\n",
    "# 1) 确保输入文件存在\n",
    "if not os.path.isfile(INPUT_PLY):\n",
    "    raise FileNotFoundError(f\"找不到输入文件：{INPUT_PLY}\")\n",
    "\n",
    "print(f\"⏳ 正在加载 PLY：{INPUT_PLY}\")\n",
    "mesh = trimesh.load(INPUT_PLY, force='mesh')\n",
    "\n",
    "print(f\"    → 顶点数：{len(mesh.vertices)}, 面数：{len(mesh.faces)}\")\n",
    "\n",
    "# 2) 导出为 GLB\n",
    "print(f\"⏳ 导出为 GLB：{OUTPUT_GLB}\")\n",
    "mesh.export(OUTPUT_GLB)\n",
    "\n",
    "print(\"✅ 导出完成！你现在可以在 Blender 里用 “File → Import → glTF 2.0” 打开它了。\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_pig",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
